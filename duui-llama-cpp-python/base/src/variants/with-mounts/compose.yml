version: '3'
services:
  llama_cpp_python:
    image: docker.texttechnologylab.org/llm/llama-cpp-python/with-mounts:latest
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - 9714:9714
    volumes:
      - /storage/nlp/models/gguf/:/app/models/
      - /storage/nlp/huggingface/:/root/.cache/huggingface/
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: [gpu]
            device_ids: ['0', '1']
